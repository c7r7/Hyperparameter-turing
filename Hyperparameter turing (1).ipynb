{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d1a82ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dae25082",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q -U keras-tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4ac9d92a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras_tuner as kt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a6e3f2d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
      "32768/29515 [=================================] - 0s 3us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
      "26427392/26421880 [==============================] - 84s 3us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
      "8192/5148 [===============================================] - 0s 1us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
      "4423680/4422102 [==============================] - 9s 2us/step\n"
     ]
    }
   ],
   "source": [
    "(img_train, label_train), (img_test, label_test) = keras.datasets.fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "73e1cb21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize pixel values between 0 and 1\n",
    "img_train = img_train.astype('float32') / 255.0\n",
    "img_test = img_test.astype('float32') / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8f20c4f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_builder(hp):\n",
    "  model = keras.Sequential()\n",
    "  model.add(keras.layers.Flatten(input_shape=(28, 28)))\n",
    "\n",
    "  # Tune the number of units in the first Dense layer\n",
    "  # Choose an optimal value between 32-512\n",
    "  hp_units = hp.Int('units', min_value=32, max_value=512, step=32)\n",
    "  model.add(keras.layers.Dense(units=hp_units, activation='relu'))\n",
    "  model.add(keras.layers.Dense(10))\n",
    "\n",
    "  # Tune the learning rate for the optimizer\n",
    "  # Choose an optimal value from 0.01, 0.001, or 0.0001\n",
    "  hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
    "\n",
    "  model.compile(optimizer=keras.optimizers.Adam(learning_rate=hp_learning_rate),\n",
    "                loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cfc4fc82",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = kt.Hyperband(model_builder,\n",
    "                     objective='val_accuracy',\n",
    "                     max_epochs=10,\n",
    "                     factor=3,\n",
    "                     directory='my_dir',\n",
    "                     project_name='intro_to_kt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "592a65e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "47076a5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 30 Complete [00h 00m 33s]\n",
      "val_accuracy: 0.8580833077430725\n",
      "\n",
      "Best val_accuracy So Far: 0.8870833516120911\n",
      "Total elapsed time: 00h 11m 03s\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "\n",
      "The hyperparameter search is complete. The optimal number of units in the first densely-connected\n",
      "layer is 192 and the optimal learning rate for the optimizer\n",
      "is 0.001.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tuner.search(img_train, label_train, epochs=50, validation_split=0.2, callbacks=[stop_early])\n",
    "\n",
    "# Get the optimal hyperparameters\n",
    "best_hps=tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "print(f\"\"\"\n",
    "The hyperparameter search is complete. The optimal number of units in the first densely-connected\n",
    "layer is {best_hps.get('units')} and the optimal learning rate for the optimizer\n",
    "is {best_hps.get('learning_rate')}.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5f770bc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.5066 - accuracy: 0.8228 - val_loss: 0.4069 - val_accuracy: 0.8550\n",
      "Epoch 2/20\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.3796 - accuracy: 0.8622 - val_loss: 0.3746 - val_accuracy: 0.8624\n",
      "Epoch 3/20\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.3408 - accuracy: 0.8755 - val_loss: 0.3445 - val_accuracy: 0.8732\n",
      "Epoch 4/20\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.3147 - accuracy: 0.8847 - val_loss: 0.3303 - val_accuracy: 0.8822\n",
      "Epoch 5/20\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2950 - accuracy: 0.8903 - val_loss: 0.3180 - val_accuracy: 0.8849\n",
      "Epoch 6/20\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2797 - accuracy: 0.8963 - val_loss: 0.3203 - val_accuracy: 0.8847\n",
      "Epoch 7/20\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2663 - accuracy: 0.9002 - val_loss: 0.3139 - val_accuracy: 0.8862\n",
      "Epoch 8/20\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2535 - accuracy: 0.9050 - val_loss: 0.3178 - val_accuracy: 0.8848\n",
      "Epoch 9/20\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2432 - accuracy: 0.9101 - val_loss: 0.3235 - val_accuracy: 0.8857\n",
      "Epoch 10/20\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2325 - accuracy: 0.9142 - val_loss: 0.3264 - val_accuracy: 0.8872\n",
      "Epoch 11/20\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2240 - accuracy: 0.9159 - val_loss: 0.3036 - val_accuracy: 0.8938\n",
      "Epoch 12/20\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2173 - accuracy: 0.9172 - val_loss: 0.3020 - val_accuracy: 0.8949\n",
      "Epoch 13/20\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2056 - accuracy: 0.9231 - val_loss: 0.3273 - val_accuracy: 0.8882\n",
      "Epoch 14/20\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2019 - accuracy: 0.9243 - val_loss: 0.3306 - val_accuracy: 0.8850\n",
      "Epoch 15/20\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1946 - accuracy: 0.9279 - val_loss: 0.3202 - val_accuracy: 0.8931\n",
      "Epoch 16/20\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1892 - accuracy: 0.9283 - val_loss: 0.3342 - val_accuracy: 0.8899\n",
      "Epoch 17/20\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1817 - accuracy: 0.9323 - val_loss: 0.3323 - val_accuracy: 0.8887\n",
      "Epoch 18/20\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1723 - accuracy: 0.9355 - val_loss: 0.3260 - val_accuracy: 0.8952\n",
      "Epoch 19/20\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1714 - accuracy: 0.9357 - val_loss: 0.3477 - val_accuracy: 0.8907\n",
      "Epoch 20/20\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1662 - accuracy: 0.9369 - val_loss: 0.3434 - val_accuracy: 0.8946\n",
      "Best epoch: 18\n"
     ]
    }
   ],
   "source": [
    "# Build the model with the optimal hyperparameters and train it on the data for 50 epochs\n",
    "model = tuner.hypermodel.build(best_hps)\n",
    "history = model.fit(img_train, label_train, epochs=20, validation_split=0.2)\n",
    "\n",
    "val_acc_per_epoch = history.history['val_accuracy']\n",
    "best_epoch = val_acc_per_epoch.index(max(val_acc_per_epoch)) + 1\n",
    "print('Best epoch: %d' % (best_epoch,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d8b7e7b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/18\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.5107 - accuracy: 0.8221 - val_loss: 0.4391 - val_accuracy: 0.8418\n",
      "Epoch 2/18\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.3814 - accuracy: 0.8608 - val_loss: 0.3706 - val_accuracy: 0.8683\n",
      "Epoch 3/18\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.3393 - accuracy: 0.8758 - val_loss: 0.3592 - val_accuracy: 0.8695\n",
      "Epoch 4/18\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.3136 - accuracy: 0.8847 - val_loss: 0.3385 - val_accuracy: 0.8797\n",
      "Epoch 5/18\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2972 - accuracy: 0.8900 - val_loss: 0.3338 - val_accuracy: 0.8796\n",
      "Epoch 6/18\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2792 - accuracy: 0.8966 - val_loss: 0.3457 - val_accuracy: 0.8750\n",
      "Epoch 7/18\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2659 - accuracy: 0.9005 - val_loss: 0.3219 - val_accuracy: 0.8872\n",
      "Epoch 8/18\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2544 - accuracy: 0.9054 - val_loss: 0.3137 - val_accuracy: 0.8878\n",
      "Epoch 9/18\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2436 - accuracy: 0.9085 - val_loss: 0.3216 - val_accuracy: 0.8894\n",
      "Epoch 10/18\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2343 - accuracy: 0.9125 - val_loss: 0.3260 - val_accuracy: 0.8857\n",
      "Epoch 11/18\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2279 - accuracy: 0.9146 - val_loss: 0.3511 - val_accuracy: 0.8749\n",
      "Epoch 12/18\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2189 - accuracy: 0.9178 - val_loss: 0.3035 - val_accuracy: 0.8932\n",
      "Epoch 13/18\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2101 - accuracy: 0.9209 - val_loss: 0.3329 - val_accuracy: 0.8872\n",
      "Epoch 14/18\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2036 - accuracy: 0.9231 - val_loss: 0.3246 - val_accuracy: 0.8850\n",
      "Epoch 15/18\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1955 - accuracy: 0.9264 - val_loss: 0.3462 - val_accuracy: 0.8878\n",
      "Epoch 16/18\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1916 - accuracy: 0.9272 - val_loss: 0.3234 - val_accuracy: 0.8940\n",
      "Epoch 17/18\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1818 - accuracy: 0.9322 - val_loss: 0.3417 - val_accuracy: 0.8894\n",
      "Epoch 18/18\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1803 - accuracy: 0.9314 - val_loss: 0.3189 - val_accuracy: 0.8963\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1cb21567cd0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hypermodel = tuner.hypermodel.build(best_hps)\n",
    "\n",
    "# Retrain the model\n",
    "hypermodel.fit(img_train, label_train, epochs=best_epoch, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ca3d282a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1/313 [..............................] - ETA: 0s - loss: 0.4161 - accuracy: 0.8750WARNING:tensorflow:Callbacks method `on_test_batch_begin` is slow compared to the batch time (batch time: 0.0000s vs `on_test_batch_begin` time: 0.0080s). Check your callbacks.\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.3521 - accuracy: 0.8909\n",
      "[test loss, test accuracy]: [0.35213911533355713, 0.8909000158309937]\n"
     ]
    }
   ],
   "source": [
    "eval_result = hypermodel.evaluate(img_test, label_test)\n",
    "print(\"[test loss, test accuracy]:\", eval_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4596cdf5",
   "metadata": {},
   "source": [
    "# OBSERVATION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb93b561",
   "metadata": {},
   "source": [
    "In this work i have understood that Accuracy will depend on number of epochs as we increase the epochs the time it will take is much more.From the above i have runned 20 epochs out of which 18th one gives more accuracy.As we increase the epochs the model may try to overfit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a79f44af",
   "metadata": {},
   "source": [
    "# CHALLENGES IN HYPERPARAMETERS TURING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f860a6",
   "metadata": {},
   "source": [
    "All the hyper parameters will depend on dataset.if the dataset is small the learning has to happen slowly. so we cant give learning rate as 0.1 or 1.0 . if the dataset is have this happens vice versa. The momentum also as we know it should be 0.9 . And if we give random state as 0 , it will work properly for most of the datasets and some will doesn't work . So all these we can't predict what to choose at what time . if we give small values the model will suffer like anything .The complexity increases and it will take lot of time . so this can be hectic work to choose the parameters. By adding more layers and more units within a layer, a deep network can represent functions of increasing complexity ,Neural networks are complex linear functions with many parameters. 6. A perceptron adds up all the weighted inputs it receives, and if it exceeds a certain value, it outputs a 1, otherwise it just outputs a 0.Neural complexity deals with lower bounds for neural resources (numbers of neurons) needed by a network to perform a given task within a given tolerance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1af3479",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
